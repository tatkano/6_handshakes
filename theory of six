import requests
from bs4 import BeautifulSoup
from collections import deque
import time

def extract_links(url):
    """Извлекаем все ссылки из статьи Википедии."""
    response = requests.get(url)
    response.raise_for_status() 
    soup = BeautifulSoup(response.text, 'html.parser')

    # Найдем все ссылки в основном блоке и блоке References
    links = set()
    # Основной блок
    for a in soup.select('#bodyContent a[href^="/wiki/"]'):
        link = a.get('href')
        if link and not link.startswith('#'):
            links.add('https://en.wikipedia.org' + link)

    # Блок References
    for ref in soup.select('#References a[href^="/wiki/"]'):
        link = ref.get('href')
        if link and not link.startswith('#'):
            links.add('https://en.wikipedia.org' + link)

    return links

def find_path(nachal_url, final_url, limit):
    """Находим путь между двумя ссылками"""
    ochered = [(nachal_url, [nachal_url])]
    visited = set()
    true_limit = 0

    while ochered:
        true_url, path = ochered.pop()
        print(f'Проверяем ссылку {true_url} из доступного пути {path}')  
              # Получаем ссылки с текущей страницы
        if true_url not in visited:
            visited.add(true_url)
            links = extract_links(true_url)
            true_limit = true_limit + 1
              # Проверка rate-limit
            if true_limit >= limit:
                print(f'Число подключений к Википедии достигло предельного значения {limit}, перерыв 3 секунды')  
                time.sleep(3)  
                true_limit = 0  
            for link in links:
                if link not in visited:
              # Добавление ссылки в очередь
                    print(f'Следующая ссылка {link} в очереди')  
                    ochered.append((link, path + [link]))
              # Проверка завершения поиска
        if true_url == final_url:
            return path
          # Проверка числа переходов
        depth = len(path)        
        if depth >= 5:
            print(f"Переходов между ссылками больше 5") 
            continue                  
    return None

def main(url10, url20, limit1):
    rez1 = find_path(url10, url20, limit1)
    rez2 = find_path(url20, url10, limit1)
    if rez1:
        print(f'Путь между ссылками url1 => {rez1} => url2')
    else:
        print('Не удалось найти путь между ссылками url1 и url2')
    if rez2:
        print(f'Путь между ссылками url2 => {rez2} => url1')
    else:
        print('Не удалось найти путь между ссылками url2 и url1')

# Основная программа
if __name__ == "__main__":
    print('Программа выполняет поиск переходов между двумя ссылками (не более шести переходов)')
    print('Первая ссылка url1 = https://en.wikipedia.org/wiki/Six_degrees_of_separation')
    print('Вторая ссылка url2 = https://en.wikipedia.org/wiki/American_Broadcasting_Company')
    url1 = "https://en.wikipedia.org/wiki/Six_degrees_of_separation"
    url2 = "https://en.wikipedia.org/wiki/American_Broadcasting_Company"
    rate_limit = 10  
    main(url1, url2, rate_limit)
